{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "from pypharma_nlp.pubmed import get_publication_sentences\n",
    "from pypharma_nlp.pubmed import get_publications\n",
    "from pypharma_nlp.pubmed import get_publications_table\n",
    "from pypharma_nlp.pubmed import get_search_results\n",
    "from pypharma_nlp.bert import get_tokens\n",
    "from pypharma_nlp.bert import get_token_probabilities\n",
    "from pypharma_nlp.bert import plot_token_probabilities\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get abstracts having the text 'T790M'\n",
    "#\n",
    "# Note: T790M is a mutation in exon 20 of the EGFR gene that \n",
    "# confers resistance to treatment with Tyrosine Kinase \n",
    "# Inhibitors\n",
    "\n",
    "records = get_publications(\"T790M[AB]\", max_results=10)\n",
    "abstracts_table = get_publications_table(records)\n",
    "display(HTML(abstracts_table.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now focus on PMID: 31442277.\n",
    "\n",
    "records = get_publications(pmids=[\"31442277\"], max_results=1)\n",
    "record = next(records)\n",
    "print(\"Title:\\n%s\" % record[\"TI\"])\n",
    "print(\"\\nAbstract:\\n%s\" % record[\"AB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get a list of sentences in this abstract\n",
    "\n",
    "sentences_generator = get_publication_sentences([record])\n",
    "sentences = next(sentences_generator)\n",
    "\n",
    "# We turn it into a nice pandas table\n",
    "\n",
    "table_records = [[s] for s in sentences]\n",
    "sentences_table = pd.DataFrame.from_records(table_records, columns=[\"Sentences\"])\n",
    "display(HTML(sentences_table.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the 3rd and 4th sentence\n",
    "\n",
    "sentence_3 = sentences[2]\n",
    "print(\"Sentence 3:\\n%s\" % sentence_3)\n",
    "sentence_4 = sentences[3]\n",
    "print(\"\\nSentence 4:\\n%s\" % sentence_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT sees these sentences a sequence of tokens. We can \n",
    "# generate the list of tokens as follows\n",
    "\n",
    "# First, we put them into a format that BERT can recognize\n",
    "formatted_text = \"[CLS] %s [SEP] %s [SEP]\" % (sentence_3, sentence_4)\n",
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we generate tokens from the formatted text.\n",
    "#\n",
    "# Tokens: These are sub-words.\n",
    "#\n",
    "# Token ID: Each sub-word has an index number in the vocabulary.\n",
    "# There are also special tokens like [CLS], which is found at the \n",
    "# start of the first sentence, and [SEP] which is found at the end \n",
    "# of every sentence.\n",
    "#\n",
    "# Segmend ID: The index of the sentence (segment), 0 for the first \n",
    "# and 1 for the second sentence.\n",
    "\n",
    "tokens, token_ids, segment_ids = get_tokens(formatted_text)\n",
    "tokens_table = pd.DataFrame.from_dict({\n",
    "    \"Token\" : tokens, \n",
    "    \"Token ID\" : token_ids, \n",
    "    \"Segment ID\" : segment_ids, \n",
    "})\n",
    "display(HTML(tokens_table.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can mask one token by setting it's value to [MASK]\n",
    "# and let BERT try to predict what it should be.\n",
    "\n",
    "probabilities, top_tokens, token_ids, masked_sentence = \\\n",
    "    get_token_probabilities(tokens, token_ids, segment_ids, 4)\n",
    "plot_token_probabilities(probabilities, top_tokens, masked_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypharma-nlp-2019",
   "language": "python",
   "name": "pypharma-nlp-2019"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
